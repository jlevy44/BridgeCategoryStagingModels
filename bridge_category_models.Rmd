---
title: "bridge_category_models"
author: "Joshua Levy"
date: "4/12/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(rstan)
library(brms)
library(bayesplot)
library(ordinal)
library(ramify)
library(tidyverse)
library(bridgesampling)
library(see)
library(stats)
library(loo)
library(bayestestR)
library(comprehenr)
library(abind)
```

# Data simulation
```{r}
sim.ord<-function(n.categories=7,
                   prevalence=0.1,
                   v=3,
                   K=5,
                   n=1000,
                   seed=42,
                   is.logit=F,
                   covariate.seed=seed,
                   B=NULL,
                   type.first.var="binary",
                   quantiles=NULL,
                   ...){
  if (is.null(quantiles)){
    quantiles<-(1:(n.categories-1))/n.categories
  }
  stopifnot(type.first.var%in%c("binary","continuous"))
  link.fn.r<-ifelse(is.logit,rlogis,rnorm)
  link.fn.q<-ifelse(is.logit,qlogis,qnorm)
  inv.link.fn<-ifelse(is.logit,plogis,pnorm)
  
  set.seed(covariate.seed)
  if (is.null(B)){B<-rnorm(K,sd=v^2)}
  set.seed(seed)
  X<-matrix(rnorm(n*K,0,1),nrow=n,ncol=K)
  if (type.first.var=='binary'){
    X[,1]<-as.numeric(runif(n)<prevalence)
  }
  mu<-as.vector(X%*%as.matrix(B))
  y.star<-link.fn.r(n,mu,1)
  cutpts<-quantile(y.star,quantiles)
  yord<-(1+apply(sapply(cutpts,function(x){y.star>x}),1,sum))
  
  return(list(x=X,#cbind(X_e,X)
              yord=yord,
              y.star=y.star,
              mu=mu,
              cutpts=cutpts))
}
```

# DGM Techniques
```{r}
dgm<-list()

dgm$none<-function(cutpts=sort(c(seq(-1.5,1.5,1),seq(-0.7,1.3,1))),
                       B=1,
                       seed=42,
                       n=1000,
                       is.logit=F,
                       treatment.effect=0,
                       n.categories=7,
                       prevalence=0.1,
                       v=3,
                       K=5,
                       covariate.seed=42,
                       type.first.var="binary",
                       quantiles=NULL,
                       ...){
  xy<-sim.ord(n.categories=n.categories,
                   prevalence=prevalence,
                   v=v,
                   K=K,
                   n=n,
                   seed=seed,
                   is.logit=is.logit,
                   covariate.seed=covariate.seed,
                   B=B,
                   type.first.var=type.first.var,
                   quantiles=quantiles)
  x<-xy$x
  yord<-xy$yord
  yblur<-yord
  return(list(x=x,yblur=yblur,yord=yord,mu=xy$mu,y.star=xy$y.star,cutpts=xy$cutpts))
}

dgm$expanded<-function(cutpts=sort(c(seq(-1.5,1.5,1),seq(-0.7,1.3,1))),
                       B=1,
                       seed=42,
                       n=1000,
                       is.logit=F,
                       treatment.effect=0,
                       n.categories=7,
                       prevalence=0.1,
                       v=3,
                       K=5,
                       covariate.seed=42,
                       type.first.var="binary",
                       quantiles=NULL,
                       ...){
   n.categories<-2*n.categories-1
   xy<-sim.ord(n.categories=n.categories,
                   prevalence=prevalence,
                   v=v,
                   K=K,
                   n=n,
                   seed=seed,
                   is.logit=is.logit,
                   covariate.seed=covariate.seed,
                   B=B,
                   type.first.var=type.first.var,
                   quantiles=quantiles)
  x<-xy$x
  yord<-xy$yord
  yblur<-(yord+1)/2
  return(list(x=x,yblur=yblur,yord=yord,mu=xy$mu,y.star=xy$y.star,cutpts=xy$cutpts))
}

dgm$blur<-function(cutpts=sort(c(seq(-1.5,1.5,1),seq(-0.7,1.3,1))),
                       B=1,
                       seed=42,
                       n=1000,
                       q=0.4,
                       p=0.8,
                       is.logit=F,
                       treatment.effect=0,
                       n.categories=7,
                       prevalence=0.1,
                       v=3,
                       K=5,
                       covariate.seed=42,
                       type.first.var="binary",
                       quantiles=NULL,
                       ...){
  
   xy<-sim.ord(n.categories=n.categories,
                   prevalence=prevalence,
                   v=v,
                   K=K,
                   n=n,
                   seed=seed,
                   is.logit=is.logit,
                   covariate.seed=covariate.seed,
                   B=B,
                   type.first.var=type.first.var,
                   quantiles=quantiles)
  cutpts<-xy$cutpts
  K<-length(cutpts)+1
  x<-xy$x
  yord<-xy$yord
  
  set.seed(seed)
  u <- runif(n,0,1)
  indblur <- (u<q)
  v <- runif(n,0,1)
  up <- 1*(v<p)
  yblur <- yord
  yblur[indblur] <- yord[indblur]+1*(up[indblur]-0.5)
  
  ind <- (yblur < 1 | yblur > K)
  if (sum(ind)>0){
    yblur[ind] <- yord[ind]
  }
  return(list(x=x,yblur=yblur,yord=yord,mu=xy$mu,y.star=xy$y.star,cutpts=xy$cutpts))
}

dgm$collapsed<-function(cutpts=sort(c(seq(-1.5,1.5,1),seq(-0.7,1.3,1))),
                       B=1,
                       seed=42,
                       n=1000,
                       q=0.4,
                       p=0.8,
                       is.logit=F,
                       treatment.effect=0,
                       n.categories=7,
                       prevalence=0.1,
                       v=3,
                       K=5,
                       covariate.seed=42,
                       type.first.var="binary",
                       quantiles=NULL,
                       ...){
  
  return(dgm$blur(cutpts,B,seed,n,q,0,is.logit,treatment.effect,n.categories,prevalence,v,K,covariate.seed,type.first.var,quantiles))
}
  
```

# data prep
```{r}
blur.group<-c("blur","mixture","set.mixture","mixture.bernoulli","collapsed")

prep<-list()
prep$expanded<-function(yblur,...){
  Y<-as.ordered(yblur*2-1)
  return(list(Y=Y,
              nthres=max(as.numeric(Y))-1))
}

prep$blur<-function(yblur,...){
  Y<-as.ordered(yblur*2)
  return(list(Y=Y,
              nthres=max(ceiling(as.numeric(yblur)))-1))
}

prep$mixture<-prep$blur

prep$set.mixture<-prep$blur

prep$mixture.bernoulli<-prep$blur

prep$collapsed<-prep$blur

prep$up<-function(yblur,...){
  yup <- as.ordered(ceiling(yblur))
  return(list(Y=yup,
              nthres=max(as.numeric(yup))-1))
}

prep$random<-function(yblur,seed=42,r=0.5,yord=NULL,n.categories=5,...){
  set.seed(seed)
  n<-length(yblur)
  yrandom <- yblur
  blur.idx <- (yblur-0.5)%%1==0
  up.random<-runif(n,0,1)<r
  yrandom[blur.idx]<-yrandom[blur.idx]+1*(up.random[blur.idx]-0.5)
  ind <- (yrandom < 1 | yrandom > n.categories)
  if (sum(ind)>0){
    yrandom[ind] <- yord[ind]
  }
  yrandom<-as.ordered(yrandom)
  return(list(Y=yrandom,
              nthres=max(as.numeric(yrandom))-1))
}

prep$down<-function(yblur,...){
  ydown <- as.ordered(floor(yblur))
  return(list(Y=ydown,
              nthres=max(as.numeric(ydown))-1))
}
```

# models
```{r}
models<-list()

models$mixture<-"functions {
   real cumulative_probit_lpmf(int y, real mu, real disc, vector thres) {
     int nthres = num_elements(thres);
     real p;
     if (y == 1) {
       p = Phi(disc * (thres[1] - mu));
     } else if (y == nthres + 1) {
       p = 1 - Phi(disc * (thres[nthres] - mu));
     } else {
       p = Phi(disc * (thres[y] - mu)) -
           Phi(disc * (thres[y - 1] - mu));
     }
     return p;
   }
   real cumulative_logit_lpmf(int y, real mu, real disc, vector thres) {
      int nthres = num_elements(thres);
      if (y == 1) {
        return exp(log_inv_logit(disc * (thres[1] - mu)));
      } else if (y == nthres + 1) {
        return exp(log1m_inv_logit(disc * (thres[nthres] - mu)));
      } else {
        return exp(log_diff_exp(
          log_inv_logit(disc * (thres[y] - mu)), 
          log_inv_logit(disc * (thres[y - 1] - mu))
        ));
      }
    }
}
data {
  int<lower=1> N;  // number of observations
  int Y[N];  // response variable
  int<lower=2> nthres;  // number of thresholds
  int<lower=1> K;  // number of population-level effects
  matrix[N, K] X;  // population-level design matrix
  int prior_only;  // should the likelihood be ignored?
  real<lower=0> var_prior;
  real<lower=0> phi_a;
  real<lower=0> phi_b;
  real<lower=0> lambda_y_min;
  real<lower=0> lambda_alpha;
  int proportional_odds;
}
transformed data {
  int Kc = K;
  matrix[N, Kc] Xc;  // centered version of X
  vector[Kc] means_X;  // column means of X before centering
  for (i in 1:K) {
    means_X[i] = mean(X[, i]);
    Xc[, i] = X[, i] - means_X[i];
  }
}
parameters {
  real<lower=0,upper=1> phi;
  real<lower=0.1> lambda;
  real<lower=0,upper=1> p;
  vector[Kc] b;  // population-level effects
  ordered[nthres] Intercept;  // temporary thresholds for centered predictors
}
transformed parameters {
  real<lower=0> alpha = lambda * phi;
  real<lower=0> beta = lambda * (1 - phi);
  real<lower=0> disc = 1;  // discrimination parameters
}
model {
  // initialize linear predictor term
  vector[N] mu = Xc * b;
  // priors including all constants
  phi ~ beta(phi_a, phi_b); // uniform on phi, could drop
  lambda ~ pareto(lambda_y_min, lambda_alpha);
  // priors including all constants
  p ~ beta(alpha, beta);
  target += normal_lpdf(Intercept | 0, var_prior);//0.1
  // likelihood including all constants
  if (!prior_only) {
    for (n in 1:N) {
      if (!proportional_odds){
        if (Y[n]%2==0){
          target += log(cumulative_probit_lpmf(Y[n]/2 | mu[n], disc, Intercept));
        }
        else {
          target += log(p*cumulative_probit_lpmf(Y[n]/2 | mu[n], disc, Intercept)+(1.-p)*cumulative_probit_lpmf(Y[n]/2 + 1 | mu[n], disc, Intercept));
        }
      } else {
        if (Y[n]%2==0){
          target += log(cumulative_logit_lpmf(Y[n]/2 | mu[n], disc, Intercept));
        }
        else {
          target += log(p*cumulative_logit_lpmf(Y[n]/2 | mu[n], disc, Intercept)+(1.-p)*cumulative_logit_lpmf(Y[n]/2 + 1 | mu[n], disc, Intercept));
        }
      }
      
      
    }
  }
}
generated quantities {
  vector[N] mu = Xc * b;
  // compute actual thresholds
  vector[nthres] b_Intercept = Intercept + dot_product(means_X, b);
  vector[N] log_lik;
  for (n in 1:N){ 
      if (!proportional_odds){
        if (Y[n]%2==0){
          log_lik[n] = log(cumulative_probit_lpmf(Y[n]/2 | mu[n], disc, Intercept));
        }
        else {
          log_lik[n] = log(p*cumulative_probit_lpmf(Y[n]/2 | mu[n], disc, Intercept)+(1.-p)*cumulative_probit_lpmf(Y[n]/2 + 1 | mu[n], disc, Intercept));
        }
      } else {
        if (Y[n]%2==0){
          log_lik[n] = log(cumulative_logit_lpmf(Y[n]/2 | mu[n], disc, Intercept));
        }
        else {
          log_lik[n] = log(p*cumulative_logit_lpmf(Y[n]/2 | mu[n], disc, Intercept)+(1.-p)*cumulative_logit_lpmf(Y[n]/2 + 1 | mu[n], disc, Intercept));
        }
      }
  }
}"

models$set.mixture<-"functions {
   real cumulative_probit_lpmf(int y, real mu, real disc, vector thres) {
     int nthres = num_elements(thres);
     real p;
     if (y == 1) {
       p = Phi(disc * (thres[1] - mu));
     } else if (y == nthres + 1) {
       p = 1 - Phi(disc * (thres[nthres] - mu));
     } else {
       p = Phi(disc * (thres[y] - mu)) -
           Phi(disc * (thres[y - 1] - mu));
     }
     return p;
   }
   real cumulative_logit_lpmf(int y, real mu, real disc, vector thres) {
      int nthres = num_elements(thres);
      if (y == 1) {
        return exp(log_inv_logit(disc * (thres[1] - mu)));
      } else if (y == nthres + 1) {
        return exp(log1m_inv_logit(disc * (thres[nthres] - mu)));
      } else {
        return exp(log_diff_exp(
          log_inv_logit(disc * (thres[y] - mu)), 
          log_inv_logit(disc * (thres[y - 1] - mu))
        ));
      }
    }
}
data {
  int<lower=1> N;  // number of observations
  int Y[N];  // response variable
  int<lower=2> nthres;  // number of thresholds
  int<lower=1> K;  // number of population-level effects
  matrix[N, K] X;  // population-level design matrix
  int prior_only;  // should the likelihood be ignored?
  real<lower=0> p;  // mixture parameters
  real<lower=0> var_prior;  
  int proportional_odds;
}
transformed data {
  int Kc = K;
  matrix[N, Kc] Xc;  // centered version of X
  vector[Kc] means_X;  // column means of X before centering
  for (i in 1:K) {
    means_X[i] = mean(X[, i]);
    Xc[, i] = X[, i] - means_X[i];
  }
}
parameters {
  vector[Kc] b;  // population-level effects
  ordered[nthres] Intercept;  // temporary thresholds for centered predictors
}
transformed parameters {
  real<lower=0> disc = 1;  // discrimination parameters
}
model {
  // initialize linear predictor term
  vector[N] mu = Xc * b;
  // priors including all constants
  target += normal_lpdf(Intercept | 0, var_prior);//0.1
  // likelihood including all constants
  if (!prior_only) {
    for (n in 1:N) {
      if (!proportional_odds){
        if (Y[n]%2==0){
          target += log(cumulative_probit_lpmf(Y[n]/2 | mu[n], disc, Intercept));
        }
        else {
          target += log(p*cumulative_probit_lpmf(Y[n]/2 | mu[n], disc, Intercept)+(1.-p)*cumulative_probit_lpmf(Y[n]/2 + 1 | mu[n], disc, Intercept));
        }
      } else {
        if (Y[n]%2==0){
          target += log(cumulative_logit_lpmf(Y[n]/2 | mu[n], disc, Intercept));
        }
        else {
          target += log(p*cumulative_logit_lpmf(Y[n]/2 | mu[n], disc, Intercept)+(1.-p)*cumulative_logit_lpmf(Y[n]/2 + 1 | mu[n], disc, Intercept));
        }
      }
    }
  }
}
generated quantities {
  vector[N] mu = Xc * b;
  // compute actual thresholds
  vector[nthres] b_Intercept = Intercept + dot_product(means_X, b);
  vector[N] log_lik;
  for (n in 1:N){ 
      if (!proportional_odds){
        if (Y[n]%2==0){
          log_lik[n] = log(cumulative_probit_lpmf(Y[n]/2 | mu[n], disc, Intercept));
        }
        else {
          log_lik[n] = log(p*cumulative_probit_lpmf(Y[n]/2 | mu[n], disc, Intercept)+(1.-p)*cumulative_probit_lpmf(Y[n]/2 + 1 | mu[n], disc, Intercept));
        }
      } else {
        if (Y[n]%2==0){
          log_lik[n] = log(cumulative_logit_lpmf(Y[n]/2 | mu[n], disc, Intercept));
        }
        else {
          log_lik[n] = log(p*cumulative_logit_lpmf(Y[n]/2 | mu[n], disc, Intercept)+(1.-p)*cumulative_logit_lpmf(Y[n]/2 + 1 | mu[n], disc, Intercept));
        }
      }
  }
}"

models$mixture.bernoulli<-"functions {
   real cumulative_probit_lpmf(int y, real mu, real disc, vector thres) {
     int nthres = num_elements(thres);
     real p;
     if (y == 1) {
       p = Phi(disc * (thres[1] - mu));
     } else if (y == nthres + 1) {
       p = 1 - Phi(disc * (thres[nthres] - mu));
     } else {
       p = Phi(disc * (thres[y] - mu)) -
           Phi(disc * (thres[y - 1] - mu));
     }
     return p;
   }
   real cumulative_logit_lpmf(int y, real mu, real disc, vector thres) {
      int nthres = num_elements(thres);
      if (y == 1) {
        return exp(log_inv_logit(disc * (thres[1] - mu)));
      } else if (y == nthres + 1) {
        return exp(log1m_inv_logit(disc * (thres[nthres] - mu)));
      } else {
        return exp(log_diff_exp(
          log_inv_logit(disc * (thres[y] - mu)), 
          log_inv_logit(disc * (thres[y - 1] - mu))
        ));
      }
    }
}
data {
  int<lower=1> N;  // number of observations
  int Y[N];  // response variable
  int<lower=2> nthres;  // number of thresholds
  int<lower=1> K;  // number of population-level effects
  matrix[N, K] X;  // population-level design matrix
  int prior_only;  // should the likelihood be ignored?
  real<lower=0> var_prior;
  real<lower=0> phi_a;
  real<lower=0> phi_b;
  real<lower=0> lambda_y_min;
  real<lower=0> lambda_alpha;
  int proportional_odds;
}
transformed data {
  int Kc = K;
  matrix[N, Kc] Xc;  // centered version of X
  vector[Kc] means_X;  // column means of X before centering
  for (i in 1:K) {
    means_X[i] = mean(X[, i]);
    Xc[, i] = X[, i] - means_X[i];
  }
}
parameters {
  real<lower=0,upper=1> phi;
  real<lower=0.1> lambda;
  real<lower=0,upper=1> p;
  vector[Kc] b;  // population-level effects
  ordered[nthres] Intercept;  // temporary thresholds for centered predictors
}
transformed parameters {
  real<lower=0> alpha = lambda * phi;
  real<lower=0> beta = lambda * (1 - phi);
  real<lower=0> disc = 1;  // discrimination parameters
}
model {
  int select_higher = 0;
  // initialize linear predictor term
  vector[N] mu = Xc * b;
  // priors including all constants
  phi ~ beta(phi_a, phi_b); // uniform on phi, could drop
  lambda ~ pareto(lambda_y_min, lambda_alpha);
  // priors including all constants
  p ~ beta(alpha, beta);
  target += normal_lpdf(Intercept | 0, var_prior);//0.1
  // likelihood including all constants
  if (!prior_only) {
    for (n in 1:N) {
      if (!proportional_odds){
        if (Y[n]%2==0){
          target += log(cumulative_probit_lpmf(Y[n]/2 | mu[n], disc, Intercept));
        }
        else {
          select_higher~bernoulli(p);
        target += log(cumulative_probit_lpmf(Y[n]/2 + select_higher | mu[n], disc, Intercept));
        }
      } else {
        if (Y[n]%2==0){
          target += log(cumulative_logit_lpmf(Y[n]/2 | mu[n], disc, Intercept));
        }
        else {
          select_higher~bernoulli(p);
        target += log(cumulative_logit_lpmf(Y[n]/2 + select_higher | mu[n], disc, Intercept));
        }
      }
    }
  }
}
generated quantities {
  int select_higher = 0;
  vector[N] mu = Xc * b;
  // compute actual thresholds
  vector[nthres] b_Intercept = Intercept + dot_product(means_X, b);
  vector[N] log_lik;
  for (n in 1:N){ 
      if (!proportional_odds){
        if (Y[n]%2==0){
          log_lik[n] = log(cumulative_probit_lpmf(Y[n]/2 | mu[n], disc, Intercept));
        }
        else {
          select_higher~bernoulli(p);
          log_lik[n] = log(cumulative_probit_lpmf(Y[n]/2 + select_higher | mu[n], disc, Intercept));
        }
      } else {
        if (Y[n]%2==0){
          log_lik[n] = log(cumulative_logit_lpmf(Y[n]/2 | mu[n], disc, Intercept));
        }
        else {
          select_higher~bernoulli(p);
          log_lik[n] = log(cumulative_logit_lpmf(Y[n]/2 + select_higher | mu[n], disc, Intercept));
        }
      }
  }
}"

models$collapsed<-"functions{
real cumulative_probit_lpmf(int y, real mu, real disc, vector thres, int diff) {
     int nthres = num_elements(thres);
     real p;
     if (y == 1) {
       p = Phi(disc * (thres[1 + diff] - mu));
     } else if ((y + diff) == (nthres + 1)) {
       p = 1 - Phi(disc * (thres[nthres - diff] - mu));
     } else {
       p = Phi(disc * (thres[y + diff] - mu)) -
           Phi(disc * (thres[y - 1] - mu));
     }
     return log(p);
}
   real cumulative_logit_lpmf(int y, real mu, real disc, vector thres, int diff) {
      int nthres = num_elements(thres);
      if (y == 1) {
        return log_inv_logit(disc * (thres[1 + diff] - mu));
      } else if ((y+diff) == (nthres + 1)) {
        return log1m_inv_logit(disc * (thres[nthres - diff] - mu));
      } else {
        return log_diff_exp(
          log_inv_logit(disc * (thres[y + diff] - mu)), 
          log_inv_logit(disc * (thres[y - 1] - mu))
        );
      }
    }
}
data {
  int<lower=1> N;  // number of observations
  int Y[N];  // response variable
  int<lower=2> nthres;  // number of thresholds
  int<lower=1> K;  // number of population-level effects
  matrix[N, K] X;  // population-level design matrix
  int prior_only;  // should the likelihood be ignored?
  real<lower=0> var_prior;
  int proportional_odds;
}
transformed data {
  int Kc = K;
  matrix[N, Kc] Xc;  // centered version of X
  vector[Kc] means_X;  // column means of X before centering
  for (i in 1:K) {
    means_X[i] = mean(X[, i]);
    Xc[, i] = X[, i] - means_X[i];
  }
}
parameters {
  vector[Kc] b;  // population-level effects
  ordered[nthres] Intercept;  // temporary thresholds for centered predictors
}
transformed parameters {
  real<lower=0> disc = 1;  // discrimination parameters
}
model {
  // initialize linear predictor term
  vector[N] mu = Xc * b;
  // priors including all constants
  target += normal_lpdf(Intercept | 0, var_prior);//0.1
  // likelihood including all constants
  if (!prior_only) {
    for (n in 1:N) {
      if (!proportional_odds){
        target += cumulative_probit_lpmf(Y[n]/2 | mu[n], disc, Intercept, Y[n]%2);
      } else {
        target += cumulative_logit_lpmf(Y[n]/2 | mu[n], disc, Intercept, Y[n]%2);
      }
      
    }
  }
}
generated quantities {
  vector[N] mu = Xc * b;
  // compute actual thresholds
  vector[nthres] b_Intercept = Intercept + dot_product(means_X, b);
  vector[N] log_lik;
  for (n in 1:N){ 
    if (!proportional_odds){
        log_lik[n] = cumulative_probit_lpmf(Y[n]/2 | mu[n], disc, Intercept, Y[n]%2);
      } else {
        log_lik[n] = cumulative_logit_lpmf(Y[n]/2 | mu[n], disc, Intercept, Y[n]%2);
      }
  }
}"

models$up<-"functions {
   real cumulative_probit_lpmf(int y, real mu, real disc, vector thres) {
     int nthres = num_elements(thres);
     
     real p;
     if (y == 1) {
       p = Phi(disc * (thres[1] - mu));
     } else if (y == nthres + 1) {
       p = 1 - Phi(disc * (thres[y - 1] - mu));
     } else {
       p = Phi(disc * (thres[y] - mu)) -
           Phi(disc * (thres[y - 1] - mu));
     }
     return log(p);
   }
   real cumulative_logit_lpmf(int y, real mu, real disc, vector thres) {
      int nthres = num_elements(thres);
      if (y == 1) {
        return log_inv_logit(disc * (thres[1] - mu));
      } else if (y == nthres + 1) {
        return log1m_inv_logit(disc * (thres[nthres] - mu));
      } else {
        return log_diff_exp(
          log_inv_logit(disc * (thres[y] - mu)), 
          log_inv_logit(disc * (thres[y - 1] - mu))
        );
      }
    }
}
data {
  int<lower=1> N;  // number of observations
  int Y[N];  // response variable
  int<lower=2> nthres;  // number of thresholds
  int<lower=1> K;  // number of population-level effects
  matrix[N, K] X;  // population-level design matrix
  int prior_only;  // should the likelihood be ignored?
  real<lower=0> var_prior;
  int proportional_odds;
}
transformed data {
  int Kc = K;
  matrix[N, Kc] Xc;  // centered version of X
  vector[Kc] means_X;  // column means of X before centering
  for (i in 1:K) {
    means_X[i] = mean(X[, i]);
    Xc[, i] = X[, i] - means_X[i];
  }
}
parameters {
  vector[Kc] b;  // population-level effects
  ordered[nthres] Intercept;  // temporary thresholds for centered predictors
}
transformed parameters {
  real<lower=0> disc = 1;  // discrimination parameters
}
model {
  // initialize linear predictor term
  vector[N] mu = Xc * b;
  // priors including all constants
  target += normal_lpdf(Intercept | 0, var_prior);//0.1
  // likelihood including all constants
  if (!prior_only) {
    for (n in 1:N) {
      if (!proportional_odds){
        target += cumulative_probit_lpmf(Y[n] | mu[n], disc, Intercept);
      } else {
        target += cumulative_logit_lpmf(Y[n] | mu[n], disc, Intercept);
      }
    }
  }
}
generated quantities {
  // compute actual thresholds
  vector[N] mu = Xc * b;
  vector[nthres] b_Intercept = Intercept + dot_product(means_X, b);
  vector[N] log_lik;
  for (n in 1:N){ 
      if (!proportional_odds){
        log_lik[n] = cumulative_probit_lpmf(Y[n] | mu[n], disc, Intercept);
      } else {
        log_lik[n] = cumulative_logit_lpmf(Y[n] | mu[n], disc, Intercept);
      }
  }
}"
models$random<-models$up
models$expanded<-models$up
models$down<-models$up
```

# simulation code
```{r}
default.hparams<-list(var_prior=1e3,
                      phi_a=1e8,
                      phi_b=1e8,
                      lambda_y_min=0.1,
                      lambda_alpha=1.5,
                      p=0.5,
                      proportional_odds=0)

cutpts_to_prob<-function(cutpts){
  p<-c(cutpts,NA)
  p[1:(length(p)-1)]<-pnorm(p[1:(length(p)-1)])
  p[length(p)]<-1
  p[2:length(p)]<-diff(p)
  return(p)
}

predict.ordinal<-function(results,return.agg.probs=F,return.full.predictive=F){
  link.fn<-ifelse(results$is.logit,plogis,pnorm)
  mu<-as.matrix(results$mcmc.matrix[,c("b[1]")])%*%t(results$data$stan.data$X-mean(results$data$stan.data$X))
  Intercepts<-results$mcmc.matrix[,grepl("Intercept",colnames(results$mcmc.matrix))&!grepl("b_Intercept",colnames(results$mcmc.matrix))]
  dim(mu)<- c(dim(mu), 1)
  mu<-mu[, , rep(1, ncol(Intercepts)+1)]
  mu_int<-mu
  for (i in 1:dim(mu)[2]){
    mu_int[,i,1:ncol(Intercepts)]<-Intercepts-mu[,i,1:ncol(Intercepts)]
  }
  p.matrix<-link.fn(mu_int)
  for (i in 2:ncol(Intercepts)){
    p.matrix[,,i]<-p.matrix[,,i]-p.matrix[,,i-1]
  }
  p.matrix[,,ncol(Intercepts)+1]<-1-p.matrix[,,ncol(Intercepts)]
  p.matrix.mean<-apply(p.matrix,c(2,3),mean)
  predictive.posterior<-NULL
  if (return.full.predictive){
    predictive.posterior<-p.matrix
  }
  results<-list(Y=results$data$stan.data$Y,
              Y.prob=p.matrix.mean,
              Y.pred=argmax(p.matrix.mean,1),
              predictive.posterior=predictive.posterior)
  if (return.agg.probs){
    p.mean<-apply(apply(p.matrix,c(1,3),mean),1,sort)
    p.ci<-apply(p.mean,1,function(x){quantile(x,c(0.025,0.975))})
    p.mean<-apply(p.mean,1,mean)
    results$p.mean<-p.mean
    results$p.ci<-p.ci
  }
  return(results)
}

dgm.prep<-function(dgm.fn,
                    prep.fn,
                    cutpts=sort(c(seq(-1.5,1.5,1),seq(-0.7,1.3,1),0)),
                    B=1,
                    seed=42,
                    n=1000,
                    q=0.4,
                    p=0.8,
                    r=0.5,
                    p.set=0.5,
                    is.logit=F,
                    treatment.effect=0,
                    n.categories=7,
                    prevalence=0.1,
                    v=3,
                    K=5,
                    covariate.seed=covariate.seed,
                    type.first.var="binary",
                    quantiles=NULL
                    ){
  dgm.res<-dgm[[dgm.fn]](cutpts=cutpts,B=B,seed=seed,n=n,q=q,p=p,is.logit=is.logit,treatment.effect=treatment.effect,n.categories=n.categories,prevalence=prevalence,v=v,K=K,covariate.seed=covariate.seed,type.first.var=type.first.var,quantiles=quantiles)
  prep.res<-prep[[prep.fn]](dgm.res$yblur,seed,r,yord=dgm.res$yord)
  stopifnot(prep.res$nthres%%2==0)
  data<-c(dgm.res,prep.res)
  data$type<-prep.fn
  data$true.p<-cutpts_to_prob(cutpts)
  if (treatment.effect==0){
    x<-data$x
  } else {
    x<-c(rep(0,length(data$x)/2),rep(1,length(data$x)/2))
  }
  data.df<-as.data.frame(cbind(x,data$Y))
  colnames(data.df)<-c(colnames(data.df)[1:(ncol(data.df)-1)],"y")
  stan.data<-make_standata(y~., data=data.df, family=cumulative(link = "probit"))
  if (prep.fn%in%blur.group){
    stan.data$Y<-stan.data$Y+1
  }
  stan.data$p<-p.set 
  stan.data$nthres<-data$nthres
  return(list(sim.data=data,stan.data=stan.data))
}

run.model<-function(data.list,
                    iter=2000,
                    cores=4,
                    seed=42,
                    chains=4,
                    verbose=0,
                    save_model_likelihood=T,
                    predict=F,
                    additional.stan.hparams=list(),
                    control=list()){
  data<-data.list$sim.data
  stan.hparams<-default.hparams
  for (nm in names(additional.stan.hparams)){
    stan.hparams[[nm]]<-additional.stan.hparams[[nm]]
  }
  stan.data<-data.list$stan.data
  stan.data<-c(stan.data,stan.hparams)
  stan_code<-models[[data$type]]
  stan_model<-stan(model_code=stan_code,data=stan.data,iter=iter,cores=min(chains,cores),seed=seed,refresh = verbose, chains = chains,control=control)
  mcmc.matrix<-as.matrix(stan_model)
  if (save_model_likelihood){
    log_lik <- extract_log_lik(stan_model)
    psis.loo <- loo(log_lik)
    bridge.sampler<-bridge_sampler(stan_model)
  } else {
    psis.loo<-NULL
    bridge.sampler<-NULL
    stan_model<-NULL
  }
  results<-list(model=stan_model,
         mcmc.matrix=mcmc.matrix[,!grepl("mu|log_lik",colnames(mcmc.matrix))],
         bridge.sampler=bridge.sampler,
         psis=psis.loo,
         data=data.list,
         predictions=NULL)
  results$is.logit<-stan.hparams$proportional_odds
  if (predict){
    results$predictions<-predict.ordinal(results,return.agg.probs = T)
  }
  return(results)
}

run.sim<-function(dgm.fn,
                    prep.fn,
                    cutpts=seq(-1.5,1.5,3/7),
                    B=c(1,2,-1),
                    seed=42,
                    n=500,
                    q=0.4,
                    p=0.8,
                    r=0.5,
                    p.set=0.5,
                    iter=4000,
                    cores=4,
                    chains=4,
                    verbose=0,
                    save_model_likelihood=F,
                    predict=F,
                    additional.stan.hparams=list(),
                    is.logit=NULL,
                    treatment.effect=0,
                    n.categories=5,
                    prevalence=0.1,
                    v=3,
                    K=3,
                    covariate.seed=42,
                    return.data.only=F,
                    type.first.var="binary",
                    control=list(adapt_delta=0.8),
                    quantiles=NULL,
                    e.q.is.0=F,
                      ){
    if (!is.null(is.logit)){additional.stan.hparams$proportional_odds<-is.logit}
    is.logit<-ifelse("proportional_odds"%in%names(additional.stan.hparams),additional.stan.hparams$proportional_odds,0)
    data.list<-dgm.prep(dgm.fn,
                        prep.fn,
                        cutpts,
                        B,
                        seed,
                        n,
                        q,
                        p,
                        r,
                        p.set,
                        is.logit,
                        treatment.effect,
                        n.categories=n.categories,
                        prevalence=prevalence,
                        v=v,
                        K=K,
                        covariate.seed=covariate.seed,
                        type.first.var=type.first.var,
                        quantiles=quantiles
                        )
    if (return.data.only){return(data.list)}
    if (e.q.is.0 & prep.fn=="expanded"){
      data.list$stan.data$Y<-as.numeric(as.character(data.list$sim.data$Y))
      data.list$stan.data$nthres<-8
    }
    results<-run.model(data.list,
                       iter,
                       cores,
                       seed,
                       chains,
                       verbose,
                       save_model_likelihood,
                       predict,
                       additional.stan.hparams,
                       control)
    return(results)
}

get.hdi<-function(x, ci=0.95){
  hdi.val<-hdi(x, ci=ci)
  return(c(mean(x),median(x),sd(x),mad(x),hdi.val$CI_low,hdi.val$CI_high))
}
sim.wrapper<-function(input.args,seed=0,no_recompile=F){
  input.args$seed<-seed
  mcmc.matrix<-do.call(run.sim,input.args)$mcmc.matrix
  res<-apply(mcmc.matrix[,grepl("b\\[",colnames(mcmc.matrix)) | colnames(mcmc.matrix)=="p"],2,get.hdi)
  rownames(res)<-c("mean","median","sd","mad","l95","u95")
  return(res)
}
execute.simulation<-function(input.args,n.sim,start.idx=1){
  results<-to_list(for (seed in start.idx:(start.idx+n.sim)) sim.wrapper(input.args,seed,(seed-start.idx)>0))
  results.arr<-abind(results, along=3)
  return(results.arr)
}

if.else<-function(expr,return.true,return.false){if (expr) {return(return.true)} else {return(return.false)}}
```